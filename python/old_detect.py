"""
Hybrid Intent Detection Service
"""
import os
import functools
import json
import hashlib
import time
from functools import lru_cache
from dotenv import load_dotenv
from .intent_rules import INTENT_RULES
from typing import Optional, Dict, Any, List, Tuple
from qdrant_client import QdrantClient
from llama_index.core import VectorStoreIndex
from llama_index.vector_stores.qdrant import QdrantVectorStore
from llama_index.embeddings.openai import OpenAIEmbedding
from llama_index.core.settings import Settings
from llama_index.core.schema import NodeWithScore
from sentence_transformers import CrossEncoder
try:
    from unidecode import unidecode
    UNIDECODE_AVAILABLE = True
except ImportError:
    UNIDECODE_AVAILABLE = False
    print("‚ö†Ô∏è unidecode kh√¥ng c√≥ s·∫µn, s·∫Ω s·ª≠ d·ª•ng normalization ƒë∆°n gi·∫£n")

load_dotenv()


class HybridIntentDetectionService:
    """
    Ph√°t hi·ªán intent t·ª´ c√¢u query.
    ∆Øu ti√™n rule-based, fallback v·ªõi vector-based.
    """

    def __init__(self):
        self.rule_patterns = INTENT_RULES
        self._load_config()

        # Ng∆∞·ª°ng chung cho rule-based
        self.high_confidence_threshold = 0.7
        self.medium_confidence_threshold = 0.3

        # Reranker threshold ƒë∆∞·ª£c tƒÉng l√™n ƒë·ªÉ tr√°nh false positive
        self.reranker_threshold = 2.0

        # Cache cho query results
        self.query_cache = {}
        self.cache_ttl = 300  # 5 ph√∫t

        # Performance tracking
        self.performance_stats = {
            "rule_calls": 0,
            "vector_calls": 0,
            "cache_hits": 0,
            "total_time": 0
        }

        # T·∫£i m√¥ h√¨nh Cross-Encoder
        try:
            print("‚è≥ ƒêang t·∫£i m√¥ h√¨nh Cross-Encoder...")
            self.cross_encoder = CrossEncoder(
                'cross-encoder/ms-marco-MiniLM-L-6-v2')
            print("‚úÖ Cross-Encoder ƒë√£ ƒë∆∞·ª£c t·∫£i th√†nh c√¥ng.")
            self.reranker_enabled = True
        except Exception as e:
            print(
                f"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫£i Cross-Encoder, Reranker s·∫Ω b·ªã v√¥ hi·ªáu h√≥a: {e}")
            self.reranker_enabled = False

        # Kh·ªüi t·∫°o vector search
        self._init_vector_search()

    def _load_config(self):
        """T·∫£i c√°c c·∫•u h√¨nh ƒë·ªông t·ª´ file JSON."""
        file_path = os.path.join(
            os.path.dirname(
                __file__), '..', 'data', 'intent-examples-augmented.json'
        )
        with open(file_path, 'r', encoding='utf-8') as f:
            intent_data = json.load(f)

        # Load ng∆∞·ª°ng tin c·∫≠y ƒë·ªông cho vector search
        self.vector_thresholds = {
            intent["id"]: intent.get("vector_confidence_threshold", 0.6)
            for intent in intent_data["intents"]
        }

    @staticmethod
    def _compare_matches(item1: Dict[str, Any], item2: Dict[str, Any]) -> int:
        """
        H√†m so s√°nh ƒë·ªÉ s·∫Øp x·∫øp c√°c intent matches.
        - ∆Øu ti√™n intent xu·∫•t hi·ªán tr∆∞·ªõc n·∫øu kho·∫£ng c√°ch v·ªã tr√≠ > 20 k√Ω t·ª±.
        - Ng∆∞·ª£c l·∫°i, ∆∞u ti√™n intent c√≥ ƒëi·ªÉm cao h∆°n.
        """
        position1, score1 = item1['position'], item1['score']
        position2, score2 = item2['position'], item2['score']

        if abs(position1 - position2) > 20:
            return position1 - position2

        if score1 > score2:
            return -1
        if score2 > score1:
            return 1
        return 0

    def _normalize_vietnamese_text(self, text: str) -> str:
        """
        Chu·∫©n h√≥a text ti·∫øng Vi·ªát ƒë·ªÉ x·ª≠ l√Ω t·ªët h∆°n c√°c tr∆∞·ªùng h·ª£p kh√¥ng d·∫•u.
        """
        if not text:
            return text

        # B∆∞·ªõc 1: Chuy·ªÉn v·ªÅ lowercase
        text = text.lower().strip()

        # B∆∞·ªõc 2: Mapping c√°c t·ª´ vi·∫øt t·∫Øt ph·ªï bi·∫øn v√† technical terms
        abbreviation_map = {
            'fpt': 'fpt university',
            'cntt': 'c√¥ng ngh·ªá th√¥ng tin',
            'it': 'information technology',
            'ai': 'artificial intelligence',
            'se': 'software engineering',
            'bkhn': 'bach khoa ha noi',
            'hcm': 'ho chi minh',
            'hn': 'ha noi',
            'ojt': 'on job training'
        }

        # B∆∞·ªõc 2.1: Mapping technical terms v·ªõi h·ªçc ph√≠
        technical_tuition_map = {
            'se program tuition': 'software engineering h·ªçc ph√≠',
            'it program tuition': 'information technology h·ªçc ph√≠',
            'ai program tuition': 'artificial intelligence h·ªçc ph√≠',
            'program tuition': 'ch∆∞∆°ng tr√¨nh h·ªçc ph√≠',
            'tuition fee': 'h·ªçc ph√≠',
            'course fee': 'h·ªçc ph√≠ kh√≥a h·ªçc',
            'program fee': 'h·ªçc ph√≠ ch∆∞∆°ng tr√¨nh'
        }

        # √Åp d·ª•ng technical tuition mapping tr∆∞·ªõc (∆∞u ti√™n cao h∆°n)
        for tech_term, replacement in technical_tuition_map.items():
            text = text.replace(tech_term, replacement)

        for abbr, full in abbreviation_map.items():
            text = text.replace(abbr, full)

        # B∆∞·ªõc 3: Mapping ti·∫øng Vi·ªát kh√¥ng d·∫•u
        vietnamese_map = {
            'hoc phi': 'h·ªçc ph√≠',
            'nganh': 'ng√†nh',
            'an toan thong tin': 'an to√†n th√¥ng tin',
            'han chot': 'h·∫°n ch√≥t',
            'nop ho so': 'n·ªôp h·ªì s∆°',
            'diem chuan': 'ƒëi·ªÉm chu·∫©n',
            'hoc bong': 'h·ªçc b·ªïng',
            'thu vien': 'th∆∞ vi·ªán',
            'ky tuc xa': 'k√Ω t√∫c x√°',
            'so sanh': 'so s√°nh',
            'tuong lai': 't∆∞∆°ng lai',
            'viec lam': 'vi·ªác l√†m'
        }

        for no_accent, with_accent in vietnamese_map.items():
            text = text.replace(no_accent, with_accent)

        # B∆∞·ªõc 4: S·ª≠ d·ª•ng unidecode n·∫øu c√≥ s·∫µn ƒë·ªÉ x·ª≠ l√Ω c√°c tr∆∞·ªùng h·ª£p kh√°c
        if UNIDECODE_AVAILABLE:
            # T·∫°o phi√™n b·∫£n kh√¥ng d·∫•u ƒë·ªÉ so s√°nh
            text_no_accent = unidecode(text)
            # Gi·ªØ nguy√™n text g·ªëc nh∆∞ng c√≥ th·ªÉ s·ª≠ d·ª•ng text_no_accent ƒë·ªÉ matching
            return text

        return text

    def _init_vector_search(self):
        """Kh·ªüi t·∫°o k·∫øt n·ªëi Qdrant v√† LlamaIndex cho vector search"""
        try:
            # K·∫øt n·ªëi Qdrant
            self.qdrant_client = QdrantClient(
                host=os.getenv("QDRANT_HOST", "localhost"),
                port=int(os.getenv("QDRANT_PORT", 6333))
            )

            # C·∫•u h√¨nh embedding model
            Settings.embed_model = OpenAIEmbedding(
                model="text-embedding-3-small",
                api_key=os.getenv("OPENAI_API_KEY"),
                api_base=os.getenv("OPENAI_BASE_URL")
            )
            Settings.llm = None

            # T·∫°o vector store
            vector_store = QdrantVectorStore(
                client=self.qdrant_client,
                collection_name="intent_examples_python_hybrid"
            )

            # T·∫°o index t·ª´ vector store
            self.vector_index = VectorStoreIndex.from_vector_store(
                vector_store=vector_store
            )

            # T·∫°o query engine v·ªõi top_k l·ªõn h∆°n cho Reranker
            self.query_engine = self.vector_index.as_query_engine(
                similarity_top_k=5
            )

            self.vector_search_enabled = True
            print("‚úÖ Vector search ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o th√†nh c√¥ng")

        except Exception as e:
            print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ kh·ªüi t·∫°o vector search: {e}")
            self.vector_search_enabled = False

    def _generate_cache_key(self, query: str) -> str:
        """T·∫°o cache key cho query"""
        return hashlib.md5(query.lower().encode()).hexdigest()

    def _is_cache_valid(self, timestamp: float) -> bool:
        """Ki·ªÉm tra cache c√≥ c√≤n h·ª£p l·ªá kh√¥ng"""
        return time.time() - timestamp < self.cache_ttl

    def _get_cached_result(self, query: str) -> Optional[Dict[str, Any]]:
        """L·∫•y k·∫øt qu·∫£ t·ª´ cache n·∫øu c√≥"""
        cache_key = self._generate_cache_key(query)
        if cache_key in self.query_cache:
            cached_data = self.query_cache[cache_key]
            if self._is_cache_valid(cached_data['timestamp']):
                self.performance_stats["cache_hits"] += 1
                return cached_data['result']
            else:
                # X√≥a cache h·∫øt h·∫°n
                del self.query_cache[cache_key]
        return None

    def _cache_result(self, query: str, result: Dict[str, Any]) -> None:
        """L∆∞u k·∫øt qu·∫£ v√†o cache"""
        cache_key = self._generate_cache_key(query)
        self.query_cache[cache_key] = {
            'result': result,
            'timestamp': time.time()
        }

        # Gi·ªõi h·∫°n cache size (ch·ªâ gi·ªØ 1000 entries g·∫ßn nh·∫•t)
        if len(self.query_cache) > 1000:
            # X√≥a 20% cache c≈© nh·∫•t
            sorted_cache = sorted(
                self.query_cache.items(),
                key=lambda x: x[1]['timestamp']
            )
            for key, _ in sorted_cache[:200]:
                del self.query_cache[key]

    def _is_irrelevant_query(self, query: str) -> bool:
        """
        Ki·ªÉm tra xem query c√≥ ph·∫£i l√† c√¢u h·ªèi ngo√†i ph·∫°m vi kh√¥ng.
        """
        irrelevant_keywords = [
            'th·ªùi ti·∫øt', 'weather', 'm∆∞a', 'n·∫Øng', 'tr·ªùi', 'rain', 'sun',
            'n·∫•u ƒÉn', 'cooking', 'm√≥n ƒÉn', 'recipe', 'ph·ªü', 'c∆°m',
            'gi√° v√†ng', 'gold price', 'ch·ª©ng kho√°n', 'stock', 'bitcoin',
            'b√≥ng ƒë√°', 'football', 'world cup', 'th·ªÉ thao', 'sport',
            '√¢m nh·∫°c', 'music', 'ca sƒ©', 'singer', 'b√†i h√°t', 'song'
        ]

        query_lower = query.lower()
        for keyword in irrelevant_keywords:
            if keyword in query_lower:
                return True
        return False

    def detect(self, query: str) -> Dict[str, Any]:
        """
        Ph√°t hi·ªán intent ch√≠nh t·ª´ c√¢u query.
        S·ª≠ d·ª•ng hybrid approach: rule-based + vector search + reranker.
        """
        start_time = time.time()

        # Step 0: Ki·ªÉm tra cache tr∆∞·ªõc
        cached_result = self._get_cached_result(query)
        if cached_result:
            return cached_result

        # Step 1: Ki·ªÉm tra c√¢u h·ªèi irrelevant
        if self._is_irrelevant_query(query):
            result = self._create_fallback_intent(0.1)
            self._cache_result(query, result)
            return result

        # Step 2: Rule-based detection
        rule_result = self._detect_intent_rule(query)
        self.performance_stats["rule_calls"] += 1

        # Early exit v·ªõi confidence r·∫•t cao (>= 0.9)
        if rule_result and rule_result["confidence"] >= 0.9:
            result = {
                "id": rule_result["intentId"],
                "confidence": rule_result["confidence"],
                "method": "rule"
            }
            self._cache_result(query, result)
            self.performance_stats["total_time"] += time.time() - start_time
            return result

        if rule_result and rule_result["confidence"] >= self.high_confidence_threshold:
            result = {
                "id": rule_result["intentId"],
                "confidence": rule_result["confidence"],
                "method": "rule"
            }
            self._cache_result(query, result)
            self.performance_stats["total_time"] += time.time() - start_time
            return result

        # Step 3: Vector-based detection + Reranking
        vector_result = self._detect_intent_vector(query)
        self.performance_stats["vector_calls"] += 1

        # Logic k·∫øt h·ª£p m·ªõi: ∆∞u ti√™n k·∫øt qu·∫£ rerank
        if vector_result and vector_result.get("method") == "rerank":
            # ƒê·∫∑t ng∆∞·ª°ng tin c·∫≠y cho ƒëi·ªÉm rerank ƒë·ªÉ tr√°nh false positives
            # ƒêi·ªÉm rerank > 2.0 m·ªõi ƒë∆∞·ª£c xem l√† ƒë√°ng tin c·∫≠y
            if vector_result["confidence"] > self.reranker_threshold:
                result = {
                    "id": vector_result["intentId"],
                    "confidence": vector_result["confidence"],
                    "method": "rerank"
                }
                self._cache_result(query, result)
                self.performance_stats["total_time"] += time.time() - \
                    start_time
                return result
            else:
                print(
                    f"   ‚ö†Ô∏è ƒêi·ªÉm Rerank ({vector_result['confidence']:.2f}) th·∫•p h∆°n ng∆∞·ª°ng ({self.reranker_threshold}), b·ªè qua.")

        # Fallback v·ªÅ rule-based n·∫øu vector/rerank kh√¥ng c√≥ k·∫øt qu·∫£ ƒë√°ng tin
        if rule_result:
            result = {
                "id": rule_result["intentId"],
                "confidence": rule_result["confidence"],
                "method": "rule"
            }
            self._cache_result(query, result)
            self.performance_stats["total_time"] += time.time() - start_time
            return result

        # Fallback cu·ªëi c√πng
        result = self._create_fallback_intent(0.1)
        self._cache_result(query, result)
        self.performance_stats["total_time"] += time.time() - start_time
        return result

    def _detect_intent_rule(self, query: str) -> Optional[Dict[str, Any]]:
        """
        Logic ph√°t hi·ªán intent b·∫±ng rule-based.
        C·∫£i ti·∫øn ƒë·ªÉ x·ª≠ l√Ω multi-intent queries b·∫±ng c√°ch ∆∞u ti√™n v·ªã tr√≠ xu·∫•t hi·ªán.
        T·ªëi ∆∞u performance b·∫±ng early exit v√† optimized matching.
        """
        # Chu·∫©n h√≥a query tr∆∞·ªõc khi x·ª≠ l√Ω
        query_normalized = self._normalize_vietnamese_text(query)
        query_lower = query_normalized.lower()
        all_matches: List[Dict[str, Any]] = []

        # S·∫Øp x·∫øp patterns theo weight gi·∫£m d·∫ßn ƒë·ªÉ ki·ªÉm tra high-priority tr∆∞·ªõc
        sorted_patterns = sorted(
            self.rule_patterns, key=lambda x: x["matchers"]["weight"], reverse=True)

        for pattern in sorted_patterns:
            score = 0
            first_match_position = float('inf')
            matchers = pattern["matchers"]

            # Keyword matching v·ªõi early exit
            keyword_found = False
            for keyword in matchers["keywords"]:
                keyword_index = query_lower.find(keyword)
                if keyword_index != -1:
                    score += 0.4 * matchers["weight"]
                    first_match_position = min(
                        first_match_position, keyword_index)
                    keyword_found = True
                    # Early exit n·∫øu ƒë√£ t√¨m th·∫•y keyword c√≥ weight cao
                    if matchers["weight"] > 1.3 and score >= 0.8:
                        break

            # Pattern matching ch·ªâ khi c·∫ßn thi·∫øt
            if keyword_found or matchers["weight"] > 1.2:
                for regex in matchers["patterns"]:
                    match = regex.search(query_lower)
                    if match:
                        score += 0.6 * matchers["weight"]
                        first_match_position = min(
                            first_match_position, match.start())

            if score > 0:
                all_matches.append({
                    "intentId": pattern["intentId"],
                    "score": min(score, 1.0),
                    "position": first_match_position
                })

                # Early exit n·∫øu t√¨m th·∫•y match v·ªõi confidence r·∫•t cao
                if score >= 1.0 and matchers["weight"] > 1.3:
                    return {
                        "intentId": pattern["intentId"],
                        "confidence": min(score, 1.0),
                    }

        if not all_matches:
            return None

        # Handle multi-intent queries
        if len(all_matches) > 1:
            all_matches.sort(key=functools.cmp_to_key(self._compare_matches))

            best_match = all_matches[0]
            # N·∫øu intent xu·∫•t hi·ªán ƒë·∫ßu ti√™n c√≥ ƒëi·ªÉm qu√° y·∫øu, fallback v·ªÅ intent c√≥ ƒëi·ªÉm cao nh·∫•t
            if best_match['score'] < 0.6:
                best_match = max(all_matches, key=lambda x: x['score'])
        else:
            best_match = all_matches[0]

        return {
            "intentId": best_match["intentId"],
            "confidence": best_match["score"],
        }

    def _rerank_with_cross_encoder(self, query: str, nodes: List[NodeWithScore]) -> Optional[Dict[str, Any]]:
        """S·ª≠ d·ª•ng Cross-Encoder ƒë·ªÉ x·∫øp h·∫°ng l·∫°i c√°c node ·ª©ng vi√™n."""
        if not self.reranker_enabled or not nodes:
            return None

        try:
            # T·∫°o c√°c c·∫∑p (query, node_text) ƒë·ªÉ ƒë∆∞a v√†o model
            sentence_pairs = [(query, node.get_text()) for node in nodes]

            # T√≠nh ƒëi·ªÉm s·ªë
            scores = self.cross_encoder.predict(sentence_pairs)

            # G·∫Øn ƒëi·ªÉm s·ªë m·ªõi v√†o c√°c node v√† t√¨m node t·ªët nh·∫•t
            best_node = None
            highest_score = -1

            print("   --- Reranker Scores ---")
            for i, node in enumerate(nodes):
                rerank_score = scores[i]
                intent_id = node.metadata.get("intent_id", "N/A")
                print(
                    f"   - Candidate: {intent_id:<20} | Score: {rerank_score:.4f}")
                if rerank_score > highest_score:
                    highest_score = rerank_score
                    best_node = node
            print("   -----------------------")

            if best_node:
                return {
                    "intentId": best_node.metadata.get("intent_id"),
                    # Chuy·ªÉn numpy.float32 th√†nh float
                    "confidence": float(highest_score),
                    "method": "rerank"
                }
        except Exception as e:
            print(f"‚ùå L·ªói trong qu√° tr√¨nh Reranking: {e}")

        return None

    def _detect_intent_vector(self, query: str) -> Optional[Dict[str, Any]]:
        """
        Ph√°t hi·ªán intent b·∫±ng Vector Search (Retriever).
        N·∫øu Reranker ƒë∆∞·ª£c b·∫≠t, n√≥ s·∫Ω ƒë∆∞·ª£c g·ªçi ƒë·ªÉ tinh ch·ªânh k·∫øt qu·∫£.
        """
        try:
            response = self.query_engine.query(query)

            if not response.source_nodes:
                print("   ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y k·∫øt qu·∫£ vector search")
                return None

            # N·∫øu reranker ƒë∆∞·ª£c b·∫≠t, s·ª≠ d·ª•ng n√≥
            if self.reranker_enabled:
                print("   üîç Vector search ƒë√£ t√¨m th·∫•y ·ª©ng vi√™n, chuy·ªÉn sang Reranker...")
                return self._rerank_with_cross_encoder(query, response.source_nodes)

            # Logic c≈© n·∫øu kh√¥ng c√≥ reranker
            best_node = response.source_nodes[0]
            intent_id = best_node.metadata.get("intent_id")
            similarity_score = best_node.score if hasattr(
                best_node, 'score') else 0.0  # M·∫∑c ƒë·ªãnh l√† 0

            print(
                f"   üéØ Vector match: {intent_id} (score: {similarity_score:.3f})")

            # L·∫•y ng∆∞·ª°ng ƒë·ªông cho intent c·ª• th·ªÉ
            dynamic_threshold = self.vector_thresholds.get(intent_id, 0.6)

            # Ch·ªâ ch·∫•p nh·∫≠n k·∫øt qu·∫£ vector search n·∫øu ƒëi·ªÉm tin c·∫≠y ƒë·ªß cao
            if intent_id and similarity_score >= dynamic_threshold:
                return {
                    "intentId": intent_id,
                    "confidence": min(similarity_score, 1.0)
                }

            print(
                f"   ‚ö†Ô∏è ƒêi·ªÉm vector search ({similarity_score:.3f}) th·∫•p h∆°n ng∆∞·ª°ng ƒë·ªông ({dynamic_threshold}), b·ªè qua k·∫øt qu·∫£.")

        except Exception as e:
            print(f"‚ùå L·ªói khi th·ª±c hi·ªán vector search: {e}")

        return None

    def _create_fallback_intent(self, confidence: float) -> Dict[str, Any]:
        """T·∫°o intent m·∫∑c ƒë·ªãnh khi kh√¥ng c√≥ match n√†o"""
        return {
            "id": "general_info",
            "confidence": confidence,
            "method": "fallback"
        }

    def get_performance_stats(self) -> Dict[str, Any]:
        """L·∫•y th·ªëng k√™ performance"""
        total_calls = self.performance_stats["rule_calls"] + \
            self.performance_stats["vector_calls"]

        return {
            "total_calls": total_calls,
            "rule_calls": self.performance_stats["rule_calls"],
            "vector_calls": self.performance_stats["vector_calls"],
            "cache_hits": self.performance_stats["cache_hits"],
            "cache_hit_rate": self.performance_stats["cache_hits"] / max(total_calls, 1) * 100,
            # ms
            "avg_response_time": self.performance_stats["total_time"] / max(total_calls, 1) * 1000,
            "cache_size": len(self.query_cache)
        }

    def reset_performance_stats(self):
        """Reset th·ªëng k√™ performance"""
        self.performance_stats = {
            "rule_calls": 0,
            "vector_calls": 0,
            "cache_hits": 0,
            "total_time": 0
        }

    def clear_cache(self):
        """X√≥a cache"""
        self.query_cache.clear()
